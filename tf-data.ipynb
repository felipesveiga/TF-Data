{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e69f535e",
   "metadata": {
    "papermill": {
     "duration": 0.003646,
     "end_time": "2023-04-25T16:28:37.231082",
     "exception": false,
     "start_time": "2023-04-25T16:28:37.227436",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 style='font-size:40px'> tf.data Pipeline</h1>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            In this notebook I'll practice my skills with the tf.data module solving Exercise 9 from Hands-On Machine Learning with Scikit-Learn and TensorFlow's Chapter 13.\n",
    "        </li>\n",
    "        <li> \n",
    "            The Exercise commands us the following:\n",
    "            <p style='font-style:italic;margin-top:10px'> \n",
    "                Load the Fashion MNIST dataset (introduced in Chapter 10); split\n",
    "it into a training set, a validation set, and a test set; shuffle the\n",
    "training set; and save each dataset to multiple TFRecord files.\n",
    "Each record should be a serialized Example protobuf with two\n",
    "features: the serialized image (use tf.io.serialize_tensor()\n",
    "to serialize each image), and the label. 11 Then use tf.data to create\n",
    "an efficient dataset for each set. Finally, use a Keras model to\n",
    "train these datasets, including a preprocessing layer to standardize\n",
    "each input feature. Try to make the input pipeline as efficient as\n",
    "possible, using TensorBoard to visualize profiling data.\n",
    "            </p>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35718d5a",
   "metadata": {
    "papermill": {
     "duration": 0.002172,
     "end_time": "2023-04-25T16:28:37.236044",
     "exception": false,
     "start_time": "2023-04-25T16:28:37.233872",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h2 style='font-size:30px'> Data Importing & Splitting</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8216821d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T16:28:37.242783Z",
     "iopub.status.busy": "2023-04-25T16:28:37.242359Z",
     "iopub.status.idle": "2023-04-25T16:28:49.452051Z",
     "shell.execute_reply": "2023-04-25T16:28:49.450558Z"
    },
    "papermill": {
     "duration": 12.217182,
     "end_time": "2023-04-25T16:28:49.455566",
     "exception": false,
     "start_time": "2023-04-25T16:28:37.238384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "29515/29515 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26421880/26421880 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "5148/5148 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4422102/4422102 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Loading the fashion_mnist dataset.\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Now, generating the validation set with `train_test_split`.\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "609647a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T16:28:49.465944Z",
     "iopub.status.busy": "2023-04-25T16:28:49.465068Z",
     "iopub.status.idle": "2023-04-25T16:28:49.636299Z",
     "shell.execute_reply": "2023-04-25T16:28:49.634787Z"
    },
    "papermill": {
     "duration": 0.179763,
     "end_time": "2023-04-25T16:28:49.639403",
     "exception": false,
     "start_time": "2023-04-25T16:28:49.459640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Storing each one of the sets in a tf.data.Dataset object.\n",
    "# The classes store 1000 elements batches. The groups' data will be put into a .tfrecord file.\n",
    "from tensorflow.data import Dataset\n",
    "train = Dataset.from_tensor_slices((X_train, y_train)).shuffle(54000).batch(1000)\n",
    "val = Dataset.from_tensor_slices((X_val, y_val)).batch(1000)\n",
    "test = Dataset.from_tensor_slices((X_test, y_test)).batch(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69d98de9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T16:28:49.648821Z",
     "iopub.status.busy": "2023-04-25T16:28:49.648371Z",
     "iopub.status.idle": "2023-04-25T16:28:49.656444Z",
     "shell.execute_reply": "2023-04-25T16:28:49.655118Z"
    },
    "papermill": {
     "duration": 0.016525,
     "end_time": "2023-04-25T16:28:49.659546",
     "exception": false,
     "start_time": "2023-04-25T16:28:49.643021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.train import BytesList, Example, Features, Feature, Int64List\n",
    "\n",
    "# \n",
    "train_files = int(len(X_train) / 1000)\n",
    "val_files = int(len(X_val) / 1000)\n",
    "test_files = int(len(X_test) / 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e547688f",
   "metadata": {
    "papermill": {
     "duration": 0.003252,
     "end_time": "2023-04-25T16:28:49.666569",
     "exception": false,
     "start_time": "2023-04-25T16:28:49.663317",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<p style='color:red'> Função para .tfrecords "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca80f52",
   "metadata": {
    "papermill": {
     "duration": 0.003065,
     "end_time": "2023-04-25T16:28:49.673047",
     "exception": false,
     "start_time": "2023-04-25T16:28:49.669982",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h2 style='font-size:30px'> </h2>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 26.858396,
   "end_time": "2023-04-25T16:28:52.807738",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-25T16:28:25.949342",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
